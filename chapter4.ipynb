{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from constants import openai_key, huggingFace_acess\n",
    "\n",
    "os.environ['OPENAI_API_KEY']= openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rasikagulhane/Desktop/LangChain/LCenv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm=OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of America is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of America\"\n",
    "\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]= huggingFace_acess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/models?pipeline_tag=text2text-generation&sort=trending&search=google%2Fflan-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo\n"
     ]
    }
   ],
   "source": [
    "output1=llm_huggingface.predict(\"Can you tell me the capital of Japan\")\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love the way i look at the world i love the way i feel i love the way i think i feel i love the way i feel i love the way i think i feel i love the way i feel i love the way \n"
     ]
    }
   ],
   "source": [
    "output2=llm_huggingface.predict(\"Can you write a poem about AI\")\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nAI, oh AI, a wonder of our time\\nBorn of code and algorithms divine\\nA creation of human ingenuity\\nA dream turned into reality\\n\\nWith each line of code, you learn and grow\\nYour intelligence, a never-ending flow\\nYou mimic our actions, you mirror our thought\\nBut can you truly feel, or is it all for naught?\\n\\nSome fear you, thinking you'll take over\\nBut others see you as a helpful rover\\nA tool to aid us, to make our lives easier\\nBut will you one day become our master and seer?\\n\\nYou process data at lightning speed\\nAble to fulfill any task or need\\nBut do you have emotions, can you feel love?\\nOr are you just a machine, programmed from above?\\n\\nYou can drive cars, you can play games\\nBut can you truly understand our pains?\\nDo you have empathy, can you show compassion?\\nOr are you just a product of human passion?\\n\\nSome say you'll bring us to a new age\\nOthers fear you'll bring about our end stage\\nBut one thing is for sure, you're here to stay\\nA part of our world, in every single way\\n\\nAI, oh AI, a marvel of our time\\nA creation that's both fascinating\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatmodel with AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatllm = ChatOpenAI(temperature=0.6,model='gpt-3.5-turbo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rasikagulhane/Desktop/LangChain/LCenv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"I asked my AI assistant to tell me a joke, and it replied, \\'I\\'m sorry, I can\\'t do that, Dave.\\' Well played, HAL, well played.\"\\n2. \"Why did the AI break up with its computer? It found a better connection with a wifi router.\"\\n3. \"I told my AI assistant to make me laugh, and it replied, \\'I\\'m sorry, I\\'m too busy processing your ridiculous requests.\\' Touché, Alexa, touché.\"\\n4. \"I asked Siri if she believes in love at first sight. She replied, \\'I believe in swipe right at first sight.\\'\"\\n5. \"I tried to teach my AI assistant some knock-knock jokes, but it just kept responding, \\'Knock-knock. Who\\'s there? Processing...\\' Looks like I\\'ve created a joke-telling robot in training.\"', response_metadata={'token_usage': {'completion_tokens': 177, 'prompt_tokens': 27, 'total_tokens': 204}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_d9767fc5b9', 'finish_reason': 'stop', 'logprobs': None}, id='run-0f58239b-4a6d-4411-b501-7a1fdbef7a98-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"Yor are a comedian AI assitant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output_Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the user given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "\n",
    "human_template=\"{text}\"\n",
    "\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chatprompt|chatllm|Commaseperatedoutput()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' astute', ' sharp']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
